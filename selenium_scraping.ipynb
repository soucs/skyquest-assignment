{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uL4LfLKXcGMU",
   "metadata": {
    "id": "uL4LfLKXcGMU"
   },
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec77ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T07:16:24.667723Z",
     "iopub.status.busy": "2022-04-17T07:16:24.666983Z",
     "iopub.status.idle": "2022-04-17T07:16:24.702821Z",
     "shell.execute_reply": "2022-04-17T07:16:24.701977Z"
    },
    "id": "dec77ed3",
    "papermill": {
     "duration": 0.0532,
     "end_time": "2022-04-17T07:16:24.705195",
     "exception": false,
     "start_time": "2022-04-17T07:16:24.651995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "import requests as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tWa8wFmMeZrL",
   "metadata": {
    "id": "tWa8wFmMeZrL"
   },
   "outputs": [],
   "source": [
    "# URL to parse\n",
    "url = 'https://www.giiresearch.com/material_report.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c8e48e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "a4c8e48e",
    "outputId": "bfa74f9e-d60d-45b3-c773-e63e615108fb",
    "papermill": {
     "duration": 0.013276,
     "end_time": "2022-04-17T07:16:24.732006",
     "exception": false,
     "start_time": "2022-04-17T07:16:24.718730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating browser instance. Using Brave Browser in this case\n",
    "driver_path = r'C:\\Users\\soumy\\Documents\\Python Notebooks\\chromedriver.exe'\n",
    "brave_path = r'C:\\Program Files\\BraveSoftware\\Brave-Browser\\Application\\brave.exe'\n",
    "option = webdriver.ChromeOptions()\n",
    "option.binary_location = brave_path\n",
    "\n",
    "driver = webdriver.Chrome(executable_path = driver_path, options=option)\n",
    "\n",
    "driver.implicitly_wait(15) \n",
    "driver.get(url)   # Opening url in browser instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7927226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to convert string date to datetime format\n",
    "\n",
    "def to_dt_format(date):\n",
    "    date = datetime.strptime(date,'%B %d, %Y')\n",
    "    return date\n",
    "def to_dt_time(date):\n",
    "    date_text = date.find_element_by_class_name('plist_info_dd2').text\n",
    "    dt_date = to_dt_format(date_text)\n",
    "    return dt_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ab456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get publish_date,title,pages and urls of objects from\n",
    "# given start_date and end_date\n",
    "\n",
    "def getData(start_date,end_date):\n",
    "    days_num = end_date-start_date\n",
    "    dates_needed = [start_date + timedelta(days=i) for i in range(days_num.days + 1)]\n",
    "\n",
    "    dates_on_page = driver.find_elements_by_class_name('plist_dateinfo')\n",
    "    dates_on_page = [to_dt_time(date) for date in dates_on_page]\n",
    "\n",
    "    if set(dates_on_page).isdisjoint(dates_needed):\n",
    "        try:\n",
    "            driver.find_element_by_class_name('btn_next').click()\n",
    "            getData(start_date,end_date)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Something happened')\n",
    "    elif not set(dates_on_page).isdisjoint(dates_needed):\n",
    "        items = driver.find_elements_by_class_name('plist_item')\n",
    "        for item in items:\n",
    "            publish_date = to_dt_time(item.find_element_by_class_name('plist_dateinfo'))\n",
    "            if publish_date<=end_date and publish_date>=start_date:\n",
    "                title = item.find_element_by_class_name('list_title').text\n",
    "                pages = item.find_element_by_class_name('plist_pageinfo').find_element_by_class_name('plist_info_dd2').text\n",
    "                url = item.find_element_by_link_text(title).get_attribute('href')\n",
    "                data.append([publish_date,title,pages,url])\n",
    "        if not dates_on_page[-1]<dates_needed[0]:\n",
    "            try:\n",
    "                driver.find_element_by_class_name('btn_next').click()\n",
    "                getData(start_date,end_date)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('Something happened')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cbf1ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify start_date and end_date (start_date<end_date)\n",
    "start_date = to_dt_format('April 11, 2022')\n",
    "end_date = to_dt_format('April 13, 2022')\n",
    "data = []\n",
    "\n",
    "# Get data using function\n",
    "data = getData(start_date,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ec923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to a dataframe\n",
    "data_df = pd.DataFrame(data,columns = ['Published Date','Report Title','No. of Pages','URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb95a4b",
   "metadata": {},
   "source": [
    "# BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6adf32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Beautifulsoup to go through the list of urls we scraped\n",
    "# and extractind description, category and table of contents info from each\n",
    "contents_list, category_list = [],[]\n",
    "for url in data_df.URL:\n",
    "    get_url = None\n",
    "    while get_url == None:\n",
    "        try:\n",
    "            get_url = r.get(url)\n",
    "            break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 5 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(5)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "    soup = bsp(get_url.content,'html.parser')\n",
    "    category = soup.find(\"a\",{\"href\":\"/material_report.shtml\"})\n",
    "    contents = soup.findAll(\"div\",attrs={\"class\",\"cntSecContent\"})\n",
    "    contents = [content.text for content in contents]\n",
    "    contents_list.append(contents)\n",
    "    category_list.append(category.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407271dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to dataframes\n",
    "contents_df = pd.DataFrame(contents_list)\n",
    "category_df = pd.DataFrame(category_list, columns = ['Category/Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "585f53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all data into output df\n",
    "output_df = pd.concat([data_df,category_df,contents_df],axis=1)\n",
    "output_df.drop(['URL'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318fc0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1b0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving output_df as csv file\n",
    "output_df.to_csv('output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0806a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "selenium-scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.6602,
   "end_time": "2022-04-17T07:16:25.365068",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-17T07:15:59.704868",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
